# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

IMPORTANT: always make sure you're on the `seldon` context in kube - I really don't want to run commands against my work cluster! A quick `ktx seldon` is enough.

## Repository Overview

This is a fully declarative Infrastructure as Code repository for managing a Kubernetes homelab called "seldon". The entire infrastructure - from OS to applications - is managed via OpenTofu/Terraform. The cluster runs on Talos Linux (immutable Kubernetes OS) in a Proxmox VM, deploying monitoring, home automation, and custom applications using Helm charts.

## Architecture

The infrastructure is single-layer, fully declarative:

### Talos Linux (Immutable OS)
- **OS Management**: Talos Linux v1.9.0, API-driven, no SSH
- **Provisioning**: VM on Proxmox (reed.local)
- **Configuration**: Declarative YAML via Terraform Talos provider
- **Updates**: Atomic OS upgrades via `talosctl`

### Terraform/OpenTofu Layer (Everything)
- **Cluster Bootstrap**: Talos machine configuration, secrets, and Kubernetes bootstrap
- **CNI**: Cilium with kube-proxy replacement and Hubble observability
- **Storage**: local-path-provisioner for dynamic volume provisioning
- **Ingress**: Traefik with hostPort :80/:443 (no LoadBalancer needed)
- **Helm Charts**: Custom charts in `terraform/charts/` and upstream charts
- **Values**: Configuration files in `terraform/values/` for each service
- **Monitoring**: Victoria Metrics, Grafana, and node-exporter
- **Authentication**: Ory Hydra OAuth 2.0 server with Oathkeeper auth proxy

## Common Commands

### Terraform Operations (Everything)
```bash
# Change to terraform directory
cd terraform

# Initialize (download providers)
tofu init

# Plan changes
tofu plan

# Apply full infrastructure (Talos + apps)
tofu apply

# Target specific resources
tofu apply -target=helm_release.cilium
tofu apply -target=helm_release.traefik

# Validate and format
tofu validate
tofu fmt -check

# Show state
tofu show
tofu state list
```

### Talos Operations (OS Management)
```bash
# Set talosconfig (generated by Terraform)
export TALOSCONFIG=./terraform/talosconfig

# Check cluster health
talosctl health --nodes 192.168.1.57

# View logs
talosctl logs --nodes 192.168.1.57 -f

# Interactive dashboard
talosctl dashboard --nodes 192.168.1.57

# Upgrade Talos OS
talosctl upgrade --nodes 192.168.1.57 --image ghcr.io/siderolabs/installer:v1.9.1

# Upgrade Kubernetes
talosctl upgrade-k8s --nodes 192.168.1.57 --to 1.35.0

# Reboot node
talosctl reboot --nodes 192.168.1.57
```

### Kubernetes Operations
```bash
# Set kubeconfig (generated by Terraform)
export KUBECONFIG=./terraform/talos-kubeconfig

# Check cluster status
kubectl get nodes
kubectl get pods --all-namespaces

# Debug specific services
kubectl -n apps logs deployment/mcp-server
kubectl -n monitoring logs deployment/victoria-metrics
kubectl -n auth logs deployment/hydra
kubectl -n auth logs deployment/oathkeeper

# Port forward for local access
kubectl port-forward -n monitoring svc/grafana 3000:3000
kubectl port-forward -n kube-system svc/hubble-ui 12000:80

# Check Cilium status
kubectl get pods -n kube-system -l k8s-app=cilium
cilium status
```

## Key Configuration

### Terraform Variables
All configuration is in `terraform/terraform.tfvars` (use `terraform/terraform.tfvars.example` as template):

**Talos Configuration:**
- `talos_version` - Talos OS version (default: v1.9.0)
- `cluster_name` - Kubernetes cluster name (default: seldon)
- `talos_controlplane_ip` - IP of Talos VM (192.168.1.57)
- `talos_hostname` - Hostname for node (default: talos-cp1)

**Application Configuration:**
- `k8s_context` - Kubernetes context (default: admin@seldon)
- OAuth credentials for Google authentication
- Cloudflare tunnel configuration
- GitHub container registry access
- Hydra OAuth 2.0 secrets (system, cookie, salt)
- PostgreSQL credentials for Hydra database

### Kubernetes Context
The Terraform-generated kubeconfig uses context `admin@seldon`. Alternatively, copy to `~/.kube/config`.

## Directory Structure

### Root Level
- `docs/` - Documentation (Proxmox VM setup, Talos Terraform guide)
- `terraform/` - All infrastructure code (OS + apps)
- `CLAUDE.md` - This file

### Terraform Directory
- `talos-cluster.tf` - Talos machine config, bootstrap, kubeconfig generation
- `cilium.tf` - CNI with kube-proxy replacement
- `local-path-provisioner.tf` - Storage provisioner (from local chart)
- `traefik.tf` - Ingress controller with hostPort
- `namespaces.tf` - Namespace creation with pod-security labels
- `monitoring.tf` - Victoria Metrics, Grafana, node-exporter
- `auth.tf` - Hydra, Oathkeeper, PostgreSQL
- `*.tf` - Other service deployments
- `charts/` - Custom Helm charts and vendored charts
  - `local-path-provisioner/` - Storage provisioner chart
  - `traefik-resources/` - Traefik middlewares, ingress routes
- `values/` - Helm values files for each service
- `variables.tf` - All variable definitions
- `terraform.tfvars` - Actual values (gitignored, contains secrets)
- `talos-kubeconfig` - Generated kubeconfig (gitignored)
- `talosconfig` - Generated talosconfig (gitignored)

## Service Namespaces

- `kube-system` - Core services (Cilium, Traefik, local-path-provisioner)
- `apps` - Application deployments (mcp-server, etc.)
- `monitoring` - Metrics and observability (Victoria Metrics, Grafana, node-exporter)
  - Pod security: **privileged** (node-exporter needs host access)
- `homelab` - Homepage and home services
- `auth` - OAuth 2.0 infrastructure (Hydra, Oathkeeper, PostgreSQL)

## Development Workflow

1. **Initial Setup**: Create Talos VM on Proxmox (see `docs/PROXMOX_TALOS_VM.md`)
2. **Bootstrap Cluster**: `tofu apply` - deploys Talos, Kubernetes, CNI, storage, and all apps
3. **Configuration Changes**: Modify `.tf` or `values/*.yaml` files, run `tofu apply`
4. **Debugging**: Use `kubectl` for apps, `talosctl` for OS-level issues
5. **Updates**: Talos/Kubernetes via `talosctl`, apps via Terraform

## Infrastructure Details

### Single-Node Configuration
- **Control plane taints removed**: `allowSchedulingOnControlPlanes = true`
- All workloads can run on the single control-plane node

### Networking
- **CNI**: Cilium with eBPF dataplane
- **Kube-proxy**: Disabled (Cilium handles service load balancing)
- **Ingress**: Traefik with `hostPort` binding to :80 and :443
- **LoadBalancer**: Not needed (using hostPort for direct access)

### Storage
- **Provisioner**: local-path-provisioner (same as K3s had)
- **Path**: `/var/local-path-provisioner` on Talos node
- **Binding**: `WaitForFirstConsumer` (volumes created when pods start)

### Security
- **Talos**: Immutable OS, no SSH, API-only access
- **Pod Security**: Baseline by default, privileged for monitoring namespace
- **Cilium**: Network policies supported (not currently configured)

## Disaster Recovery

### Backup Critical Files
- `terraform/terraform.tfvars` - All secrets and configuration
- `terraform/terraform.tfstate` - Infrastructure state
- Store securely offline (both contain sensitive data)

### Full Rebuild
1. Recreate Proxmox VM (see docs)
2. Update IP in `terraform.tfvars` if changed
3. Run `tofu apply`
4. Entire cluster rebuilds from scratch (~10 minutes)

### Cluster State Loss
If you lose Terraform state but cluster is running:
```bash
# Import existing resources
tofu import talos_machine_secrets.this machine_secrets
# ... import other resources as needed
```

## YAML File Preferences

- Prefer separate YAML files over multi-document files with `---` separators
- Instead of combining deployment and service in one file, create separate `deployment.yaml` and `service.yaml` files
- This applies to all Kubernetes manifests and Helm chart templates

## Documentation

- `docs/PROXMOX_TALOS_VM.md` - Complete VM setup guide with optimal settings
- `docs/TALOS_TERRAFORM_SETUP.md` - Terraform bootstrap workflow and operations guide
